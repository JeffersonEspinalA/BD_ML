{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNO4xHaILN3Z4aFjOd25peS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeffersonEspinalA/BD_ML/blob/main/Modelo_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iv28oAFOQoKM"
      },
      "outputs": [],
      "source": [
        "def _discriminator(dict_size, se=False):\n",
        "    # inputs\n",
        "    labels = Input(shape=(1,))\n",
        "    voxels_inp = Input(shape=(32,32,32))\n",
        "    voxels = Lambda(lambda x: K.expand_dims(x))(voxels_inp)\n",
        "\n",
        "    # label embedding\n",
        "    embs = Embedding(dict_size, 64, input_length=1)(labels)\n",
        "    embs = Flatten()(embs)\n",
        "    embs = dense_layer(embs, 1024, act='lrelu', bn=False)\n",
        "\n",
        "    # conv layers\n",
        "    out = conv_layer(voxels, 32, 5, 1, act='lrelu', bn=False, se=se)\n",
        "    out = conv_layer(out, 32, act='lrelu', bn=False, se=se)\n",
        "    out = conv_layer(out, 64, act='lrelu', bn=False, se=se)\n",
        "    out = conv_layer(out, 128, act='lrelu', bn=False, se=se)\n",
        "    out = conv_layer(out, 256, act='lrelu', bn=False, se=se)\n",
        "    out = Flatten()(out)\n",
        "    out = dense_layer(out, 1024, act='lrelu', bn=False)\n",
        "    out = Concatenate()([out, embs])\n",
        "    out = dense_layer(out, 1024, act='lrelu', bn=False)\n",
        "    out = dense_layer(out, 512, act='lrelu', bn=False)\n",
        "    out = dense_layer(out, 1, act=None, bn=False)\n",
        "\n",
        "    return Model((voxels_inp, labels), out)\n",
        "\n",
        "def _generator_v(dict_size):\n",
        "    # inputs\n",
        "    labels = Input(shape=(1,))\n",
        "    voxels_inp = Input(shape=(32,32,32))\n",
        "    voxels = Lambda(lambda x: K.expand_dims(x))(voxels_inp)\n",
        "\n",
        "    # label embedding\n",
        "    embs = Embedding(dict_size, 64, input_length=1)(labels)\n",
        "    embs = Flatten()(embs)\n",
        "    embs = dense_layer(embs, 1024)\n",
        "\n",
        "    # conv layers\n",
        "    out = conv_layer(voxels, 32, 5, 1)\n",
        "    out = conv_layer(out, 32)\n",
        "    out = conv_layer(out, 64)\n",
        "    out = conv_layer(out, 128)\n",
        "    out = conv_layer(out, 256)\n",
        "\n",
        "    out = Flatten()(out)\n",
        "    out = dense_layer(out, 1024)\n",
        "    out = Concatenate()([out, embs])\n",
        "    out = dense_layer(out, 1024) # as in D\n",
        "    out = dense_layer(out, 2*2*2*256)\n",
        "    out = Lambda(lambda x: K.reshape(x, (-1,2,2,2,256)))(out)\n",
        "\n",
        "    out = conv_layer(out, 256, transpose=True)\n",
        "    out = conv_layer(out, 128, transpose=True)\n",
        "    out = conv_layer(out, 64, transpose=True)\n",
        "    out = conv_layer(out, 32, transpose=True)\n",
        "\n",
        "    out = conv_layer(out, 1, 5, 1, act='tanh', bn=False)\n",
        "    out = Lambda(lambda x: K.squeeze(x, 4))(out)\n",
        "\n",
        "    return Model((voxels_inp, labels), out)\n",
        "\n",
        "def _generator_u(dict_size, se=False):\n",
        "    # inputs\n",
        "    labels = Input(shape=(1,))\n",
        "    voxels_inp = Input(shape=(32,32,32))\n",
        "    voxels = Lambda(lambda x: K.expand_dims(x))(voxels_inp)\n",
        "\n",
        "    # label embedding\n",
        "    embs = Embedding(dict_size, 64, input_length=1)(labels)\n",
        "    embs = Flatten()(embs)\n",
        "    embs = dense_layer(embs, 1024)\n",
        "\n",
        "    # conv layers\n",
        "    encoder1 = conv_layer(voxels, 32, 5, 1, se=se)\n",
        "    encoder2 = conv_layer(encoder1, 32, se=se)\n",
        "    encoder3 = conv_layer(encoder2, 64, se=se)\n",
        "    encoder4 = conv_layer(encoder3, 128, se=se)\n",
        "    encoder5 = conv_layer(encoder4, 256, se=se)\n",
        "\n",
        "    mix = Flatten()(encoder5)\n",
        "    mix = dense_layer(mix, 1024)\n",
        "    mix = Concatenate()([mix, embs])\n",
        "    mix = dense_layer(mix, 1024) # as in D\n",
        "    mix = dense_layer(mix, 2*2*2*256)\n",
        "    mix = Lambda(lambda x: K.reshape(x, (-1,2,2,2,256)))(mix)\n",
        "    mix = Concatenate()([mix, encoder5])\n",
        "\n",
        "    decoder1 = conv_layer(mix, 128, transpose=True, se=se)\n",
        "    decoder1 = Concatenate()([decoder1, encoder4])\n",
        "    decoder2 = conv_layer(decoder1, 64, transpose=True, se=se)\n",
        "    decoder2 = Concatenate()([decoder2, encoder3])\n",
        "    decoder3 = conv_layer(decoder2, 32, transpose=True, se=se)\n",
        "    decoder3 = Concatenate()([decoder3, encoder2])\n",
        "    decoder4 = conv_layer(decoder3, 32, transpose=True, se=se)\n",
        "    decoder4 = Concatenate()([decoder4, encoder1])\n",
        "\n",
        "    out = conv_layer(decoder4, 1, 5, 1, act='tanh', bn=False)\n",
        "    out = Lambda(lambda x: K.squeeze(x, 4))(out)\n",
        "\n",
        "    return Model((voxels_inp, labels), out)"
      ]
    }
  ]
}